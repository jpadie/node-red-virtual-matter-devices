{
  "version": 3,
  "sources": ["../../../../src/protocol/interaction/AttributeDataEncoder.ts"],
  "sourcesContent": ["/**\n * @license\n * Copyright 2022-2024 Matter.js Authors\n * SPDX-License-Identifier: Apache-2.0\n */\nimport { MatterFlowError } from \"../../common/MatterError.js\";\nimport { AttributeId } from \"../../datatype/AttributeId.js\";\nimport { ClusterId } from \"../../datatype/ClusterId.js\";\nimport { EndpointNumber } from \"../../datatype/EndpointNumber.js\";\nimport { NodeId } from \"../../datatype/NodeId.js\";\nimport { Logger } from \"../../log/Logger.js\";\nimport { ArraySchema } from \"../../tlv/TlvArray.js\";\nimport { TlvEncodingOptions, TlvSchema, TlvStream, TypeFromSchema } from \"../../tlv/TlvSchema.js\";\nimport {\n    TlvAttributePath,\n    TlvAttributeReport,\n    TlvAttributeReportData,\n    TlvDataReport,\n    TlvEventData,\n    TlvEventReport,\n} from \"./InteractionProtocol.js\";\n\ntype FullAttributePath = {\n    nodeId?: NodeId;\n    endpointId: EndpointNumber;\n    clusterId: ClusterId;\n    attributeId: AttributeId;\n    dataVersion?: number;\n};\n\n/** Type for TlvAttributeReport where the real data are represented with the schema and the JS value. */\nexport type AttributeReportPayload = Omit<TypeFromSchema<typeof TlvAttributeReport>, \"attributeData\"> & {\n    attributeData?: AttributeDataPayload;\n    hasFabricSensitiveData: boolean;\n};\n\n/** Type for TlvAttributeReportData where the real data are represented with the schema and the JS value. */\ntype AttributeDataPayload = Omit<TypeFromSchema<typeof TlvAttributeReportData>, \"data\"> & {\n    schema: TlvSchema<any>;\n    payload: any;\n};\n\n/** Type for TlvEventReport where the real data are represented with the schema and the JS value. */\nexport type EventReportPayload = Omit<TypeFromSchema<typeof TlvEventReport>, \"eventData\"> & {\n    eventData?: EventDataPayload;\n    hasFabricSensitiveData: boolean;\n};\n\n/** Type for TlvEventData where the real data are represented with the schema and the JS value. */\nexport type EventDataPayload = Omit<TypeFromSchema<typeof TlvEventData>, \"data\"> & {\n    schema: TlvSchema<any>;\n    payload: any;\n};\n\n/** Type for TlvDataReport where the real data are represented with the schema and the JS value. */\nexport type DataReportPayload = Omit<TypeFromSchema<typeof TlvDataReport>, \"attributeReports\" | \"eventReports\"> & {\n    attributeReportsPayload?: AttributeReportPayload[];\n    eventReportsPayload?: EventReportPayload[];\n};\n\n/** Encodes an AttributeReportPayload into a TlvStream (used for TlvAny type). */\nexport function encodeAttributePayload(\n    attributePayload: AttributeReportPayload,\n    options?: TlvEncodingOptions,\n): TlvStream {\n    const { attributeData, attributeStatus } = attributePayload;\n    if (attributeData === undefined) {\n        return TlvAttributeReport.encodeTlv({ attributeStatus });\n    }\n\n    const { path, schema, payload, dataVersion } = attributeData;\n    return TlvAttributeReport.encodeTlv({\n        attributeData: { path, data: schema.encodeTlv(payload, options), dataVersion },\n    });\n}\n\n/** Encodes an EventReportPayload into a TlvStream (used for TlvAny type). */\nexport function encodeEventPayload(eventPayload: EventReportPayload, options?: TlvEncodingOptions): TlvStream {\n    const { eventData, eventStatus } = eventPayload;\n    if (eventData === undefined) {\n        return TlvEventReport.encodeTlv({ eventStatus });\n    }\n\n    const {\n        path,\n        schema,\n        payload,\n        eventNumber,\n        deltaEpochTimestamp,\n        epochTimestamp,\n        deltaSystemTimestamp,\n        systemTimestamp,\n        priority,\n    } = eventData;\n    return TlvEventReport.encodeTlv({\n        eventData: {\n            path,\n            data: schema.encodeTlv(payload, options),\n            priority,\n            systemTimestamp,\n            deltaSystemTimestamp,\n            deltaEpochTimestamp,\n            epochTimestamp,\n            eventNumber,\n        },\n    });\n}\n\n/** Return if an AttributeReportPayload can be chunked or not. */\nexport function canAttributePayloadBeChunked(attributePayload: AttributeReportPayload): boolean {\n    const { attributeData } = attributePayload;\n    if (attributeData === undefined) {\n        return false;\n    }\n    const {\n        schema,\n        payload,\n        path: { listIndex },\n    } = attributeData;\n    return schema instanceof ArraySchema && Array.isArray(payload) && payload.length > 0 && listIndex === undefined;\n}\n\n/** Chunk an AttributeReportPayload into multiple AttributeReportPayloads. */\nexport function chunkAttributePayload(attributePayload: AttributeReportPayload): AttributeReportPayload[] {\n    const { hasFabricSensitiveData, attributeData } = attributePayload;\n    if (attributeData === undefined) {\n        throw new MatterFlowError(\n            `Cannot chunk an AttributePayload with just a attributeStatus: ${Logger.toJSON(attributePayload)}`,\n        );\n    }\n    const { schema, path, dataVersion, payload } = attributeData;\n    if (!(schema instanceof ArraySchema) || !Array.isArray(payload)) {\n        throw new MatterFlowError(\n            `Cannot chunk an AttributePayload with attributeData that is not an array: ${Logger.toJSON(\n                attributePayload,\n            )}`,\n        );\n    }\n    const chunks = new Array<AttributeReportPayload>();\n    chunks.push({\n        hasFabricSensitiveData: hasFabricSensitiveData,\n        attributeData: { schema, path: { ...path, listIndex: undefined }, payload: [], dataVersion },\n    });\n    payload.forEach(element => {\n        chunks.push({\n            hasFabricSensitiveData: hasFabricSensitiveData,\n            attributeData: {\n                schema: schema.elementSchema,\n                path: { ...path, listIndex: null },\n                payload: element,\n                dataVersion,\n            },\n        });\n    });\n\n    // If the path of the initial AttributePayload was not compressed, we should compress the chunked data\n    // TODO Enable once Tag Compression is supported https://github.com/project-chip/connectedhomeip/issues/29359\n    /*\n    if (path.enableTagCompression !== true) {\n        return compressAttributeDataReportTags(chunks);\n    }\n    */\n\n    return chunks;\n}\n\n/**\n * Sort function to sort AttributeReportPayloads by nodeId/EndpointId/clusterId/attributeId to generate an ideal\n * ground for tag compression.\n */\nexport function sortAttributeDataByPath(data1: AttributeReportPayload, data2: AttributeReportPayload) {\n    const { path: path1 } = data1.attributeData ?? data1.attributeStatus ?? {};\n    const { path: path2 } = data2.attributeData ?? data2.attributeStatus ?? {};\n    if (path1?.nodeId !== undefined && path2?.nodeId !== undefined && path1.nodeId !== path2.nodeId) {\n        return path1.nodeId < path2.nodeId ? -1 : 1;\n    }\n    if (path1?.endpointId !== undefined && path2?.endpointId !== undefined && path1.endpointId !== path2.endpointId) {\n        return path1.endpointId < path2.endpointId ? -1 : 1;\n    }\n    if (path1?.clusterId !== undefined && path2?.clusterId !== undefined && path1.clusterId !== path2.clusterId) {\n        return path1.clusterId < path2.clusterId ? -1 : 1;\n    }\n    if (\n        path1?.attributeId !== undefined &&\n        path2?.attributeId !== undefined &&\n        path1.attributeId !== path2.attributeId\n    ) {\n        return path1.attributeId < path2.attributeId ? -1 : 1;\n    }\n    return 0;\n}\n\n/** Sort and use Tag compression to compress a list of AttributeReportPayloads. */\nexport function compressAttributeDataReportTags(data: AttributeReportPayload[]) {\n    let lastFullPath: FullAttributePath | undefined;\n\n    return data.sort(sortAttributeDataByPath).map(({ hasFabricSensitiveData, attributeData, attributeStatus }) => {\n        if (attributeData !== undefined) {\n            const { path, dataVersion } = attributeData;\n            const compressedPath = compressPath(path, dataVersion, lastFullPath);\n            const { enableTagCompression } = compressedPath.path;\n            attributeData = {\n                ...attributeData,\n                path: compressedPath.path,\n                dataVersion: enableTagCompression ? undefined : dataVersion,\n            };\n            lastFullPath = compressedPath.lastFullPath;\n        }\n        if (attributeStatus !== undefined) {\n            const { path } = attributeStatus;\n            const compressedPath = compressPath(path, undefined, lastFullPath);\n            attributeStatus = { ...attributeStatus, path: compressedPath.path };\n            lastFullPath = compressedPath.lastFullPath;\n        }\n        return { hasFabricSensitiveData, attributeData, attributeStatus };\n    });\n}\n\n/** Helper method to compress one path and preserve the state for the next path. */\nfunction compressPath(\n    path: TypeFromSchema<typeof TlvAttributePath>,\n    dataVersion: number | undefined,\n    lastFullPath: FullAttributePath | undefined,\n): { path: TypeFromSchema<typeof TlvAttributePath>; lastFullPath?: FullAttributePath } {\n    const { nodeId, endpointId, clusterId, attributeId } = path;\n\n    // Should never happen but typing likes it better that way\n    if (endpointId === undefined || clusterId === undefined || attributeId === undefined) {\n        return { path, lastFullPath };\n    }\n\n    const newFullPath = {\n        path: { ...path, enableTagCompression: undefined },\n        lastFullPath: { nodeId, endpointId, clusterId, attributeId, dataVersion },\n    };\n    // We have no stored Full path, so we take this as starting point\n    if (lastFullPath === undefined) {\n        return newFullPath;\n    }\n\n    // When dataVersion differs we can't compress\n    if (dataVersion !== undefined && dataVersion !== lastFullPath.dataVersion) {\n        return newFullPath;\n    }\n\n    // Based on Specs in DataReports AttributeId and CLusterId SHALL always be present in the path\n    let compressedElements = 0;\n    // Assume we can compress elements in the path\n    const compressedPath = { ...path, enableTagCompression: true };\n    if (endpointId === lastFullPath.endpointId) {\n        delete compressedPath.endpointId;\n        compressedElements++;\n    }\n    if (nodeId === lastFullPath.nodeId && nodeId !== undefined) {\n        // No need to count if undefined\n        delete compressedPath.nodeId;\n        compressedElements++;\n    }\n\n    // Nothing was compressed, so we use this as new full path\n    if (compressedElements === 0) {\n        return newFullPath;\n    }\n\n    return { path: compressedPath, lastFullPath };\n}\n"],
  "mappings": "AAAA;AAAA;AAAA;AAAA;AAAA;AAKA,SAAS,uBAAuB;AAKhC,SAAS,cAAc;AACvB,SAAS,mBAAmB;AAE5B;AAAA,EAEI;AAAA,EAIA;AAAA,OACG;AAyCA,SAAS,uBACZ,kBACA,SACS;AACT,QAAM,EAAE,eAAe,gBAAgB,IAAI;AAC3C,MAAI,kBAAkB,QAAW;AAC7B,WAAO,mBAAmB,UAAU,EAAE,gBAAgB,CAAC;AAAA,EAC3D;AAEA,QAAM,EAAE,MAAM,QAAQ,SAAS,YAAY,IAAI;AAC/C,SAAO,mBAAmB,UAAU;AAAA,IAChC,eAAe,EAAE,MAAM,MAAM,OAAO,UAAU,SAAS,OAAO,GAAG,YAAY;AAAA,EACjF,CAAC;AACL;AAGO,SAAS,mBAAmB,cAAkC,SAAyC;AAC1G,QAAM,EAAE,WAAW,YAAY,IAAI;AACnC,MAAI,cAAc,QAAW;AACzB,WAAO,eAAe,UAAU,EAAE,YAAY,CAAC;AAAA,EACnD;AAEA,QAAM;AAAA,IACF;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ,IAAI;AACJ,SAAO,eAAe,UAAU;AAAA,IAC5B,WAAW;AAAA,MACP;AAAA,MACA,MAAM,OAAO,UAAU,SAAS,OAAO;AAAA,MACvC;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACJ;AAAA,EACJ,CAAC;AACL;AAGO,SAAS,6BAA6B,kBAAmD;AAC5F,QAAM,EAAE,cAAc,IAAI;AAC1B,MAAI,kBAAkB,QAAW;AAC7B,WAAO;AAAA,EACX;AACA,QAAM;AAAA,IACF;AAAA,IACA;AAAA,IACA,MAAM,EAAE,UAAU;AAAA,EACtB,IAAI;AACJ,SAAO,kBAAkB,eAAe,MAAM,QAAQ,OAAO,KAAK,QAAQ,SAAS,KAAK,cAAc;AAC1G;AAGO,SAAS,sBAAsB,kBAAoE;AACtG,QAAM,EAAE,wBAAwB,cAAc,IAAI;AAClD,MAAI,kBAAkB,QAAW;AAC7B,UAAM,IAAI;AAAA,MACN,iEAAiE,OAAO,OAAO,gBAAgB,CAAC;AAAA,IACpG;AAAA,EACJ;AACA,QAAM,EAAE,QAAQ,MAAM,aAAa,QAAQ,IAAI;AAC/C,MAAI,EAAE,kBAAkB,gBAAgB,CAAC,MAAM,QAAQ,OAAO,GAAG;AAC7D,UAAM,IAAI;AAAA,MACN,6EAA6E,OAAO;AAAA,QAChF;AAAA,MACJ,CAAC;AAAA,IACL;AAAA,EACJ;AACA,QAAM,SAAS,IAAI,MAA8B;AACjD,SAAO,KAAK;AAAA,IACR;AAAA,IACA,eAAe,EAAE,QAAQ,MAAM,EAAE,GAAG,MAAM,WAAW,OAAU,GAAG,SAAS,CAAC,GAAG,YAAY;AAAA,EAC/F,CAAC;AACD,UAAQ,QAAQ,aAAW;AACvB,WAAO,KAAK;AAAA,MACR;AAAA,MACA,eAAe;AAAA,QACX,QAAQ,OAAO;AAAA,QACf,MAAM,EAAE,GAAG,MAAM,WAAW,KAAK;AAAA,QACjC,SAAS;AAAA,QACT;AAAA,MACJ;AAAA,IACJ,CAAC;AAAA,EACL,CAAC;AAUD,SAAO;AACX;AAMO,SAAS,wBAAwB,OAA+B,OAA+B;AAClG,QAAM,EAAE,MAAM,MAAM,IAAI,MAAM,iBAAiB,MAAM,mBAAmB,CAAC;AACzE,QAAM,EAAE,MAAM,MAAM,IAAI,MAAM,iBAAiB,MAAM,mBAAmB,CAAC;AACzE,MAAI,OAAO,WAAW,UAAa,OAAO,WAAW,UAAa,MAAM,WAAW,MAAM,QAAQ;AAC7F,WAAO,MAAM,SAAS,MAAM,SAAS,KAAK;AAAA,EAC9C;AACA,MAAI,OAAO,eAAe,UAAa,OAAO,eAAe,UAAa,MAAM,eAAe,MAAM,YAAY;AAC7G,WAAO,MAAM,aAAa,MAAM,aAAa,KAAK;AAAA,EACtD;AACA,MAAI,OAAO,cAAc,UAAa,OAAO,cAAc,UAAa,MAAM,cAAc,MAAM,WAAW;AACzG,WAAO,MAAM,YAAY,MAAM,YAAY,KAAK;AAAA,EACpD;AACA,MACI,OAAO,gBAAgB,UACvB,OAAO,gBAAgB,UACvB,MAAM,gBAAgB,MAAM,aAC9B;AACE,WAAO,MAAM,cAAc,MAAM,cAAc,KAAK;AAAA,EACxD;AACA,SAAO;AACX;AAGO,SAAS,gCAAgC,MAAgC;AAC5E,MAAI;AAEJ,SAAO,KAAK,KAAK,uBAAuB,EAAE,IAAI,CAAC,EAAE,wBAAwB,eAAe,gBAAgB,MAAM;AAC1G,QAAI,kBAAkB,QAAW;AAC7B,YAAM,EAAE,MAAM,YAAY,IAAI;AAC9B,YAAM,iBAAiB,aAAa,MAAM,aAAa,YAAY;AACnE,YAAM,EAAE,qBAAqB,IAAI,eAAe;AAChD,sBAAgB;AAAA,QACZ,GAAG;AAAA,QACH,MAAM,eAAe;AAAA,QACrB,aAAa,uBAAuB,SAAY;AAAA,MACpD;AACA,qBAAe,eAAe;AAAA,IAClC;AACA,QAAI,oBAAoB,QAAW;AAC/B,YAAM,EAAE,KAAK,IAAI;AACjB,YAAM,iBAAiB,aAAa,MAAM,QAAW,YAAY;AACjE,wBAAkB,EAAE,GAAG,iBAAiB,MAAM,eAAe,KAAK;AAClE,qBAAe,eAAe;AAAA,IAClC;AACA,WAAO,EAAE,wBAAwB,eAAe,gBAAgB;AAAA,EACpE,CAAC;AACL;AAGA,SAAS,aACL,MACA,aACA,cACmF;AACnF,QAAM,EAAE,QAAQ,YAAY,WAAW,YAAY,IAAI;AAGvD,MAAI,eAAe,UAAa,cAAc,UAAa,gBAAgB,QAAW;AAClF,WAAO,EAAE,MAAM,aAAa;AAAA,EAChC;AAEA,QAAM,cAAc;AAAA,IAChB,MAAM,EAAE,GAAG,MAAM,sBAAsB,OAAU;AAAA,IACjD,cAAc,EAAE,QAAQ,YAAY,WAAW,aAAa,YAAY;AAAA,EAC5E;AAEA,MAAI,iBAAiB,QAAW;AAC5B,WAAO;AAAA,EACX;AAGA,MAAI,gBAAgB,UAAa,gBAAgB,aAAa,aAAa;AACvE,WAAO;AAAA,EACX;AAGA,MAAI,qBAAqB;AAEzB,QAAM,iBAAiB,EAAE,GAAG,MAAM,sBAAsB,KAAK;AAC7D,MAAI,eAAe,aAAa,YAAY;AACxC,WAAO,eAAe;AACtB;AAAA,EACJ;AACA,MAAI,WAAW,aAAa,UAAU,WAAW,QAAW;AAExD,WAAO,eAAe;AACtB;AAAA,EACJ;AAGA,MAAI,uBAAuB,GAAG;AAC1B,WAAO;AAAA,EACX;AAEA,SAAO,EAAE,MAAM,gBAAgB,aAAa;AAChD;",
  "names": []
}
